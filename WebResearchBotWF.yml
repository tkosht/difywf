app:
  description: ''
  icon: earth_asia
  icon_background: '#E0F2FE'
  mode: advanced-chat
  name: WebResearchBotWF
  use_icon_as_answer_icon: false
kind: app
version: 0.1.2
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
    opening_statement: ''
    retriever_resource:
      enabled: false
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        isInIteration: false
        sourceType: start
        targetType: llm
      id: start-source-1722881600298-target
      selected: false
      source: start
      sourceHandle: source
      target: '1722881600298'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: tool
      id: 1723370699352-source-1723370611661-target
      selected: false
      source: '1723370699352'
      sourceHandle: source
      target: '1723370611661'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: tool
        targetType: code
      id: 1723370611661-source-1723375137144-target
      selected: false
      source: '1723370611661'
      sourceHandle: source
      target: '1723375137144'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: llm
      id: 1723376740359-source-llm-target
      selected: false
      source: '1723376740359'
      sourceHandle: source
      target: llm
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: llm
      id: 1723379291001-source-1723378799590-target
      selected: false
      source: '1723379291001'
      sourceHandle: source
      target: '1723378799590'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 17230462851560-source-1723375030258-target
      selected: false
      source: '17230462851560'
      sourceHandle: source
      target: '1723375030258'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: code
      id: 1723378799590-source-1724248650613-target
      source: '1723378799590'
      sourceHandle: source
      target: '1724248650613'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: 17260571626980-source-17230462851560-target
      source: '17260571626980'
      sourceHandle: source
      target: '17230462851560'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: code
      id: 1724248650613-source-1726481800506-target
      source: '1724248650613'
      sourceHandle: source
      target: '1726481800506'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: 1722881600298-source-1726483567005-target
      source: '1722881600298'
      sourceHandle: source
      target: '1726483567005'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: if-else
      id: 1726483567005-source-1726483573233-target
      source: '1726483567005'
      sourceHandle: source
      target: '1726483573233'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: 1726483573233-true-1723370699352-target
      source: '1726483573233'
      sourceHandle: 'true'
      target: '1723370699352'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: 1726483573233-false-17264840707000-target
      source: '1726483573233'
      sourceHandle: 'false'
      target: '17264840707000'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 17264840707000-source-1726483254480-target
      source: '17264840707000'
      sourceHandle: source
      target: '1726483254480'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: llm
      id: 1723376740359-source-17230461613590-target
      source: '1723376740359'
      sourceHandle: source
      target: '17230461613590'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: code
      id: 17230461613590-source-1726857729968-target
      source: '17230461613590'
      sourceHandle: source
      target: '1726857729968'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: llm
      id: 1726857729968-source-17260566859520-target
      source: '1726857729968'
      sourceHandle: source
      target: '17260566859520'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: code
      id: llm-source-1726857729968-target
      source: llm
      sourceHandle: source
      target: '1726857729968'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: llm
      id: 1726857729968-source-17260571626980-target
      source: '1726857729968'
      sourceHandle: source
      target: '17260571626980'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: tool
        targetType: code
      id: 1723370611661-source-1723379291001-target
      source: '1723370611661'
      sourceHandle: source
      target: '1723379291001'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: code
      id: 1723375137144-source-1724248650613-target
      source: '1723375137144'
      sourceHandle: source
      target: '1724248650613'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: 17260566859520-source-17230462851560-target
      source: '17260566859520'
      sourceHandle: source
      target: '17230462851560'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: code
      id: 1726481800506-source-1723376740359-target
      source: '1726481800506'
      sourceHandle: source
      target: '1723376740359'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        selected: false
        title: START
        type: start
        variables: []
      height: 41
      id: start
      position:
        x: -91.12566973335174
        y: 282
      positionAbsolute:
        x: -91.12566973335174
        y: 282
      selected: false
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        memory:
          query_prompt_template: '{{#sys.query#}}

            {{#1722881600298.text#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
        model:
          completion_params:
            stop: []
          mode: chat
          name: gemini-1.5-pro-latest
          provider: google
        prompt_template:
        - id: d68abc6b-6825-41c0-8419-edeec9f97611
          role: system
          text: 'When answer to user:

            - If you don''t know, just say that you don''t know.

            - If you don''t know when you are not sure, ask for clarification.

            Avoid mentioning that you obtained the information from the context.

            And answer according to the language of the user''s question.


            指示された内容に関してプロとして答えるのに最も適切なロールを設定し明示します。その後、本問い合わせに関する<検索結果>、<検索結果の要点>を参考に、その問いに対して重要な観点を洗い出し（明示的に書き下し）それらについて、プロとしてそれら観点を単独および複合的、横断的な見解を踏まえ
            Markdown 形式に整形・整理されたシンクタンクが作成するレポートのレベルの完成度でレポートします



            <検索結果>

            {{#1723376740359.result#}}

            </検索結果>


            <検索結果の要点>

            {{#1723378799590.text#}}

            </検索結果の要点>


            '
        selected: false
        title: LLM Analysis Gemini
        type: llm
        vision:
          configs:
            detail: high
          enabled: true
          variable_selector:
          - sys
          - files
      height: 74
      id: llm
      position:
        x: 2815.0009822733396
        y: 282
      positionAbsolute:
        x: 2815.0009822733396
        y: 282
      selected: false
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: Query Analysis
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
            size: 50
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gemini-1.5-flash-latest
          provider: google
        prompt_template:
        - id: 9fd9e1ba-ab45-436e-8cd0-4281a3c22b32
          role: system
          text: '# 要求

            あなたは、RAGプロンプトのプロフェッショナルです。以下の「# ユーザからの問い合わせ」の「背景情報」を正確に抽出し、より適切な問い合わせ文章を作成し以下の「#
            出力フォーマット」に厳密に従い出力とします



            # ユーザからの問い合わせ

            ```

            {{#sys.query#}}

            ```


            # 出力フォーマット


            ```

            ## ユーザからの問い合わせ

            {{#sys.query#}}


            ## 背景情報（推定）

            <<ここに、正確に抽出した背景情報を記載します>>


            ## 問い合わせの改善案

            <<ここに、「背景情報」を踏まえたより適切と考えられる内容を記載します>>


            ```

            '
        selected: false
        title: LLM Query Analysis
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
      height: 99
      id: '1722881600298'
      position:
        x: 256.02353300596207
        y: 282
      positionAbsolute:
        x: 256.02353300596207
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}

            {{#1722881600298.text#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
        model:
          completion_params:
            stop: []
          mode: chat
          name: gpt-4o
          provider: openai
        prompt_template:
        - id: d68abc6b-6825-41c0-8419-edeec9f97611
          role: system
          text: 'When answer to user:

            - If you don''t know, just say that you don''t know.

            - If you don''t know when you are not sure, ask for clarification.

            Avoid mentioning that you obtained the information from the context.

            And answer according to the language of the user''s question.


            指示された内容に関してプロとして答えるのに最も適切なロールを設定し明示します。その後、本問い合わせに関する<検索結果>、<検索結果の要点>を参考に、その問いに対して重要な観点を洗い出し（明示的に書き下し）それらについて、プロとしてそれら観点を単独および複合的、横断的な見解を踏まえ
            Markdown 形式に整形・整理されたシンクタンクが作成するレポートのレベルの完成度でレポートします



            <検索結果>

            {{#1723376740359.result#}}

            </検索結果>


            <検索結果の要点>

            {{#1723378799590.text#}}

            </検索結果の要点>

            '
        selected: false
        title: LLM Analysis GPT-4o
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
          variable_selector:
          - sys
          - files
      height: 74
      id: '17230461613590'
      position:
        x: 2815.0009822733396
        y: 391.26534802469354
      positionAbsolute:
        x: 2815.0009822733396
        y: 391.26534802469354
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}

            {{#1722881600298.text#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
        model:
          completion_params:
            stop: []
          mode: chat
          name: gemini-1.5-pro-latest
          provider: google
        prompt_template:
        - id: d68abc6b-6825-41c0-8419-edeec9f97611
          role: system
          text: 'When answer to user:

            - If you don''t know, just say that you don''t know.

            - If you don''t know when you are not sure, ask for clarification.

            Avoid mentioning that you obtained the information from the context.

            And answer according to the language of the user''s question.




            指示された内容に関してプロとして答えるのに最も適切なロールを設定し明示します。その後、<検索結果>を参考に、その問いに対して重要な観点を洗い出し（明示的に書き下し）それらについて、プロとしてそれら観点を単独および複合的、横断的な見解を踏まえ
            Markdown 形式に整形・整理されたシンクタンクが作成するレポートのレベルの完成度で日本語でレポートします。

            その時、<検索結果> および 提案された回答レポート（<answer-candidate-N>タグの中身）、それら回答レポートそれぞれに対するレビュー（<answer-review-N>タグの中身）を参考にして、一流プロのレベルとして最も最適かつ完全なレポートになるように完成させます。それでは、はりきっていきましょう！



            <検索結果>

            {{#1723376740359.result#}}

            </検索結果>


            <answer-candidate-1>

            {{#llm.text#}}

            </answer-candidate-1>


            <answer-candidate-1>

            {{#17230461613590.text#}}

            </answer-candidate-1>



            <answer-review-1>

            {{#17260566859520.text#}}

            </answer-review-1>


            <answer-review-2>

            {{#17260571626980.text#}}

            </answer-review-2>


            '
        selected: false
        title: LLM Merge Gemini
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
          variable_selector:
          - sys
          - files
      height: 74
      id: '17230462851560'
      position:
        x: 3788.7456543595354
        y: 282
      positionAbsolute:
        x: 3788.7456543595354
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        provider_id: google
        provider_name: google
        provider_type: builtin
        selected: false
        title: GoogleSearch
        tool_configurations: {}
        tool_label: GoogleSearch
        tool_name: google_search
        tool_parameters:
          query:
            type: mixed
            value: '{{#1723370699352.text#}}'
        type: tool
      height: 41
      id: '1723370611661'
      position:
        x: 1200.3117973399178
        y: 391.26534802469354
      positionAbsolute:
        x: 1200.3117973399178
        y: 391.26534802469354
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: Keyword Generator
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: false
            size: 50
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gpt-4o-mini
          provider: openai
        prompt_template:
        - id: 54fd2a07-ebe8-41d6-b651-737dce78e9e2
          role: system
          text: '# 要求

            あなたは、RAGプロンプトのプロフェッショナルです。以下の「# ユーザ問い合わせの分析結果」内の情報からWeb上で検索すべき情報やメタ情報を検索して取得・抽出するためのキーワード候補（集合）を厳選してください



            # ユーザ問い合わせの分析結果


            ```

            {{#1722881600298.text#}}

            ```


            # 出力形式

            キーワード集合（最大 5 単語）を半角スペースで区切った文字列のみを出力とします


            ```

            Keyword1 Keyword2 ... KeywordN

            ```


            出力例：

            今日 天気 東京 麻布十番

            '
        selected: false
        title: LLM KeyWord Generator
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
      height: 99
      id: '1723370699352'
      position:
        x: 1200.3117973399178
        y: 282
      positionAbsolute:
        x: 1200.3117973399178
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '---


          # クエリ解析結果 [Gemini 1.5 Flash]

          {{#1722881600298.text#}}


          ---


          # クエリ分類結果 [Gemini 1.5 Flash]

          {{#1726483567005.text#}}


          ---


          # キーワード抽出結果 [GPT-4o]

          {{#1723370699352.text#}}


          ---

          # 検索結果要点

          {{#1723378799590.text#}}


          ---


          # 案１[Gemini 1.5 Pro]

          {{#llm.text#}}


          ---


          # 案２[GPT-4o]

          {{#17230461613590.text#}}


          ---


          # レビュー１[Gemini 1.5 Pro]

          {{#17260566859520.text#}}


          ---


          # レビュー２[GPT-4o]

          {{#17260571626980.text#}}


          ---


          # 最終案 [Gemini 1.5 Pro]

          {{#17230462851560.text#}}



          '
        desc: ''
        selected: false
        title: 調査結果レポート
        type: answer
        variables: []
      height: 258
      id: '1723375030258'
      position:
        x: 4133.4341058676755
        y: 282
      positionAbsolute:
        x: 4133.4341058676755
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "\ndef main(search_results: dict) -> list:\n    urls = [obj[\"link\"\
          ] for obj in search_results[0][\"organic_results\"]]\n\n    return {\n \
          \       \"result\": urls,\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: array[string]
        selected: false
        title: コード - 検索結果URLリスト生成
        type: code
        variables:
        - value_selector:
          - '1723370611661'
          - json
          variable: search_results
      height: 41
      id: '1723375137144'
      position:
        x: 1535.080586565123
        y: 282
      positionAbsolute:
        x: 1535.080586565123
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "\ndef main(outputs: list[str]) -> str:\n    contents = []\n    content\
          \ = \"\\n\\n\".join(outputs)\n    return {\n        \"result\": content,\n\
          \    }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: string
        selected: false
        title: コード - 検索結果コンテンツの結合
        type: code
        variables:
        - value_selector:
          - '1726481800506'
          - result
          variable: outputs
      height: 41
      id: '1723376740359'
      position:
        x: 2503.6135286239837
        y: 282
      positionAbsolute:
        x: 2503.6135286239837
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
            size: 50
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gemini-1.5-flash-latest
          provider: google
        prompt_template:
        - id: e01a18fe-357d-4026-9da4-2eb5d874c22e
          role: system
          text: '# 要求

            「# 検索結果結果一覧」を Markdown 形式に整形して出力します


            # 検索結果一覧

            {{#1723379291001.result#}}


            # 出力形式

            Markdown 形式で、箇条書きとリンクを有効にして出力します

            '
        selected: false
        title: LLM - List to Markdown
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
      height: 74
      id: '1723378799590'
      position:
        x: 1535.080586565123
        y: 426.76847125268057
      positionAbsolute:
        x: 1535.080586565123
        y: 426.76847125268057
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "\ndef main(search_results: dict) -> str:\n    return {\n        \"\
          result\": str(search_results),\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: string
        selected: false
        title: コード - 検索結果のテキスト化
        type: code
        variables:
        - value_selector:
          - '1723370611661'
          - json
          variable: search_results
      height: 41
      id: '1723379291001'
      position:
        x: 1535.080586565123
        y: 350.14562234706796
      positionAbsolute:
        x: 1535.080586565123
        y: 350.14562234706796
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "\ndef main(urls: list[str]) -> list[str]:\n    _urls = [u for u in\
          \ urls if u.split(\".\")[-1] not in [\"pdf\"]]\n    return {\n        \"\
          result\": _urls,\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: array[string]
        selected: false
        title: コード URLフィルタ
        type: code
        variables:
        - value_selector:
          - '1723375137144'
          - result
          variable: urls
      height: 41
      id: '1724248650613'
      position:
        x: 1885.9960010855214
        y: 282
      positionAbsolute:
        x: 1885.9960010855214
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}

            {{#1722881600298.text#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
        model:
          completion_params:
            stop: []
          mode: chat
          name: gemini-1.5-pro-latest
          provider: google
        prompt_template:
        - id: d68abc6b-6825-41c0-8419-edeec9f97611
          role: system
          text: '以下<指示>タグの内容に従って作成された複数のレポート（<report-N>タグそれぞれの中身）をレビューしてください。

            本問い合わせに関する<検索結果>、<検索結果の要点>を参考に、レポートをレビューするために最も適したレビュー観点を複数かつ複合的に抽出し、各レポート<report-N>の内容それぞれに対して、レビュー観点毎に定性評価および定量評価（0点から5点）をそれらの評価になる理由とともに明記して、レビューレポートとしてまとめます。


            <指示>

            指示された内容に関してプロとして答えるのに最も適切なロールを設定し明示します。その後、本問い合わせに関する<検索結果>、<検索結果の要点>を参考に、その問いに対して重要な観点を洗い出し（明示的に書き下し）それらについて、プロとしてそれら観点を単独および複合的、横断的な見解を踏まえ
            Markdown 形式に整形・整理されたシンクタンクが作成するレポートのレベルの完成度でレポートします

            </指示>



            <検索結果>

            {{#1723376740359.result#}}

            </検索結果>


            <検索結果の要点>

            {{#1723378799590.text#}}

            </検索結果の要点>



            <report-1>

            {{#llm.text#}}

            </report-1>


            <report-2>

            {{#17230461613590.text#}}

            </report-2>

            '
        selected: false
        title: LLM Review Gemini 1.5 Pro
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
          variable_selector:
          - sys
          - files
      height: 74
      id: '17260566859520'
      position:
        x: 3462.6322846600633
        y: 282
      positionAbsolute:
        x: 3462.6322846600633
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}

            {{#1722881600298.text#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
        model:
          completion_params:
            stop: []
          mode: chat
          name: gpt-4o
          provider: openai
        prompt_template:
        - id: d68abc6b-6825-41c0-8419-edeec9f97611
          role: system
          text: 'When answer to user:

            - If you don''t know, just say that you don''t know.

            - If you don''t know when you are not sure, ask for clarification.

            Avoid mentioning that you obtained the information from the context.

            And answer according to the language of the user''s question.


            以下<指示>タグの内容に従って作成された複数のレポート（<report-N>タグそれぞれの中身）をレビューしてください。

            <検索結果>を参考に、レポートをレビューするために最も適したレビュー観点を複数かつ複合的に抽出し、各レポート<report-N>の内容それぞれに対して、レビュー観点毎に定性評価および定量評価（0点から5点）をそれらの評価になる理由とともに明記して、レビューレポートとしてまとめます。


            <指示>

            指示された内容に関してプロとして答えるのに最も適切なロールを設定し明示します。その後、<検索結果>を参考に、その問いに対して重要な観点を洗い出し（明示的に書き下し）それらについて、プロとしてそれら観点を単独および複合的、横断的な見解を踏まえ
            Markdown 形式に整形・整理されたシンクタンクが作成するレポートのレベルの完成度でレポートします

            </指示>



            <検索結果>

            {{#1723376740359.result#}}

            </検索結果>



            <report-1>

            {{#llm.text#}}

            </report-1>


            <report-2>

            {{#17230461613590.text#}}

            </report-2>

            '
        selected: false
        title: LLM Review GPT-4o
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
          variable_selector:
          - sys
          - files
      height: 74
      id: '17260571626980'
      position:
        x: 3462.6322846600633
        y: 391.26534802469354
      positionAbsolute:
        x: 3462.6322846600633
        y: 391.26534802469354
      selected: true
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import requests\nfrom bs4 import BeautifulSoup, Tag, NavigableString\n\
          \n\ndef html_to_markdown(element):\n    markdown = ''\n    if isinstance(element,\
          \ NavigableString):\n        return element.strip()\n    elif isinstance(element,\
          \ Tag):\n        if element.name == 'h1':\n            return '# ' + ''.join([html_to_markdown(e)\
          \ for e in element.contents]) + '\\n\\n'\n        elif element.name == 'h2':\n\
          \            return '## ' + ''.join([html_to_markdown(e) for e in element.contents])\
          \ + '\\n\\n'\n        elif element.name == 'h3':\n            return '###\
          \ ' + ''.join([html_to_markdown(e) for e in element.contents]) + '\\n\\\
          n'\n        elif element.name == 'h4':\n            return '#### ' + ''.join([html_to_markdown(e)\
          \ for e in element.contents]) + '\\n\\n'\n        elif element.name == 'p':\n\
          \            return ''.join([html_to_markdown(e) for e in element.contents])\
          \ + '\\n\\n'\n        elif element.name == 'ul':\n            return ''.join(['*\
          \ ' + html_to_markdown(li) + '\\n' for li in element.find_all('li')]) +\
          \ '\\n'\n        elif element.name == 'ol':\n            return ''.join([f'{i+1}.\
          \ ' + html_to_markdown(li) + '\\n' for i, li in enumerate(element.find_all('li'))])\
          \ + '\\n'\n        elif element.name == 'strong' or element.name == 'b':\n\
          \            return '**' + ''.join([html_to_markdown(e) for e in element.contents])\
          \ + '**'\n        elif element.name == 'em' or element.name == 'i':\n  \
          \          return '*' + ''.join([html_to_markdown(e) for e in element.contents])\
          \ + '*'\n        elif element.name == 'a':\n            href = element.get('href',\
          \ '')\n            text = ''.join([html_to_markdown(e) for e in element.contents])\n\
          \            return f'[{text}]({href})'\n        else:\n            return\
          \ ''.join([html_to_markdown(e) for e in element.contents])\n    else:\n\
          \        return ''\n\ndef fetch_and_convert(url) -> str:\n    try:\n   \
          \     response = requests.get(url, timeout=(5, 10))  # 接続タイムアウト5秒、応答タイムアウト10秒\n\
          \        response.raise_for_status()\n    except requests.exceptions.HTTPError\
          \ as errh:\n        print(f\"HTTPエラー: {errh}\")\n        raise errh\n  \
          \  except requests.exceptions.ConnectionError as errc:\n        print(f\"\
          接続エラー: {errc}\")\n        raise errc\n    except requests.exceptions.Timeout\
          \ as errt:\n        print(f\"タイムアウトエラー: {errt}\")\n        raise errt\n\
          \    except requests.exceptions.RequestException as err:\n        print(f\"\
          その他のエラー: {err}\")\n        raise err\n\n    soup = BeautifulSoup(response.content,\
          \ 'html.parser')\n    markdown = html_to_markdown(soup.body)\n    max_letters\
          \ = 10000\n    return markdown[:max_letters]\n\n\ndef main(urls: list[str])\
          \ -> str:\n    markdowns = []\n    for url in urls:\n        print(f\"URL:\
          \ {url}\\n\")\n        try:\n            md = fetch_and_convert(url)\n \
          \           markdowns.append(md)\n        except Exception as e:\n     \
          \       continue\n\n    return {\n        \"result\": markdowns[:5],\n \
          \   }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: array[string]
        selected: false
        title: コード HTTP to Markdowns
        type: code
        variables:
        - value_selector:
          - '1724248650613'
          - result
          variable: urls
      height: 41
      id: '1726481800506'
      position:
        x: 2190.8643978231275
        y: 282
      positionAbsolute:
        x: 2190.8643978231275
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '---


          # クエリ解析結果 [Gemini 1.5 Flash]

          {{#1722881600298.text#}}


          ---


          # クエリ解析結果 [Gemini 1.5 Flash]

          {{#1726483567005.text#}}


          ---


          # 回答


          {{#17264840707000.text#}}'
        desc: ''
        selected: false
        title: 単純回答
        type: answer
        variables: []
      height: 137
      id: '1726483254480'
      position:
        x: 1535.080586565123
        y: 584.1641607583592
      positionAbsolute:
        x: 1535.080586565123
        y: 584.1641607583592
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gemini-1.5-flash-latest
          provider: google
        prompt_template:
        - id: 918292ab-a23b-42cf-95c6-331f66fdf8d6
          role: system
          text: '# 要件


            「# ユーザからの問い合わせ」、「# ユーザからの問い合わせの解析結果」に適切に回答をするために、

            Web調査を必要とする場合は、"research" とだけ出力します

            文脈などから適切に回答ができるなどWeb調査が不要な場合は、"answer" とだけ出力します



            # ユーザからの問い合わせ


            {{#sys.query#}}



            # ユーザからの問い合わせの解析結果


            {{#1722881600298.text#}}

            '
        selected: false
        title: LLM 分類
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
      height: 74
      id: '1726483567005'
      position:
        x: 586.8011271783762
        y: 282
      positionAbsolute:
        x: 586.8011271783762
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        cases:
        - case_id: 'true'
          conditions:
          - comparison_operator: contains
            id: 1faa73e1-bd62-4fd3-a6a2-1717490d0d42
            value: research
            varType: string
            variable_selector:
            - '1726483567005'
            - text
          id: 'true'
          logical_operator: and
        desc: ''
        selected: false
        title: IF/ELSE
        type: if-else
      height: 95
      id: '1726483573233'
      position:
        x: 889.8011271783762
        y: 282
      positionAbsolute:
        x: 889.8011271783762
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        memory:
          query_prompt_template: ''
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
            size: 50
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: gemini-1.5-pro-latest
          provider: google
        prompt_template:
        - id: a2739bf8-eb59-4141-ae36-7efd14538f69
          role: system
          text: '# 要件


            「# ユーザからの問い合わせ」、「# ユーザからの問い合わせの解析結果」に最も適した回答を正確に作成します。


            # ユーザからの問い合わせ


            {{#sys.query#}}



            # ユーザからの問い合わせの解析結果


            {{#1722881600298.text#}}

            '
        selected: false
        title: LLM 回答作成
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
      height: 74
      id: '17264840707000'
      position:
        x: 1200.3117973399178
        y: 584.1641607583592
      positionAbsolute:
        x: 1200.3117973399178
        y: 584.1641607583592
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "\ndef main(arg: str) -> dict:\n    return {\n        \"result\": arg,\n\
          \    }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: string
        selected: false
        title: コード Fake
        type: code
        variables:
        - value_selector:
          - sys
          - query
          variable: arg
      height: 41
      id: '1726857729968'
      position:
        x: 3130.7153229357614
        y: 282
      positionAbsolute:
        x: 3130.7153229357614
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: -863.9315315538838
      y: 100.43632758891096
      zoom: 0.6344480884184368
